repo_name = "TheBloke/vicuna-13B-v1.5-16K-GPTQ"
repo_revision = "gptq-4bit-32g-actorder_True"
model_name = "vicuna-13B-v1.5-16K-GPTQ"
model_basename = "gptq_model-4bit-32g.safetensors"
max_new_tokens = 8192
token_repetition_penalty_max = 1.176470
temperature = 0.01
top_p = 0
top_k = 20
max_seq_len = 16384
compress_pos_emb = 4
